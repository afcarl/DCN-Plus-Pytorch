{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = json.load(open('train-v1.1.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qn, an = 0, 0\n",
    "skipped = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sequence):\n",
    "    tokens = [token.replace(\"``\", '\"').replace(\"''\", '\"') for token in nltk.word_tokenize(sequence)]\n",
    "    return [x for x in tokens] # .encode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_idx_map(context, context_tokens):\n",
    "    acc = ''\n",
    "    current_token_idx = 0\n",
    "    token_map = dict()\n",
    "    for char_idx, char in enumerate(context):\n",
    "        if char != ' ':\n",
    "            acc += char\n",
    "            context_token = str(context_tokens[current_token_idx])\n",
    "            if acc == context_token:\n",
    "                syn_start = char_idx - len(acc) + 1\n",
    "                token_map[syn_start] = [acc, current_token_idx]\n",
    "                acc = ''\n",
    "                current_token_idx += 1\n",
    "    return token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-dd6f91bd50db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                \u001b[0man\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Skipped {} question/answer pairs in {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tier' is not defined"
     ]
    }
   ],
   "source": [
    " for articles_id in range(len(dataset['data'])):\n",
    "    article_paragraphs = dataset['data'][articles_id]['paragraphs']\n",
    "    for pid in range(len(article_paragraphs)):\n",
    "        context = article_paragraphs[pid]['context']\n",
    "        # The following replacements are suggested in the paper\n",
    "        # BidAF (Seo et al., 2016)\n",
    "        context = context.replace(\"''\", '\" ')\n",
    "        context = context.replace(\"``\", '\" ')\n",
    "\n",
    "        context_tokens = tokenize(context)\n",
    "        answer_map = token_idx_map(context, context_tokens)\n",
    "\n",
    "        qas = article_paragraphs[pid]['qas']\n",
    "        for qid in range(len(qas)):\n",
    "            question = qas[qid]['question']\n",
    "            question_tokens = tokenize(question)\n",
    "\n",
    "            answers = qas[qid]['answers']\n",
    "            qn += 1\n",
    "\n",
    "            num_answers = list(range(1))\n",
    "\n",
    "            for ans_id in num_answers:\n",
    "                # it contains answer_start, text\n",
    "                text = qas[qid]['answers'][ans_id]['text']\n",
    "                a_s = qas[qid]['answers'][ans_id]['answer_start']\n",
    "\n",
    "                text_tokens = tokenize(text)\n",
    "\n",
    "                answer_start = qas[qid]['answers'][ans_id]['answer_start']\n",
    "\n",
    "                answer_end = answer_start + len(text)\n",
    "\n",
    "                last_word_answer = len(text_tokens[-1]) # add one to get the first char\n",
    "\n",
    "                try:\n",
    "                    a_start_idx = answer_map[answer_start][1]\n",
    "\n",
    "                    a_end_idx = answer_map[answer_end - last_word_answer][1]\n",
    "                    \n",
    "                    train_data.append([context_tokens,question_tokens,text_tokens,a_start_idx,a_end_idx])\n",
    "                    \n",
    "                    # remove length restraint since we deal with it later\n",
    "#                     context_file.write(' '.join(context_tokens) + '\\n')\n",
    "#                     question_file.write(' '.join(question_tokens) + '\\n')\n",
    "#                     text_file.write(' '.join(text_tokens) + '\\n')\n",
    "#                     span_file.write(' '.join([str(a_start_idx), str(a_end_idx)]) + '\\n')\n",
    "\n",
    "                except Exception as e:\n",
    "                    skipped += 1\n",
    "\n",
    "                an += 1\n",
    "\n",
    "print(\"Skipped {} question/answer pairs in {}\".format(skipped, tier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
